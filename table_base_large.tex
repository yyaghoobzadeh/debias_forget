%%% Compares 


\begin{table*}[ht]
\small
\centering
\begin{tabular}{lcccccc}
\toprule
\textbf{Model} & \multicolumn{2}{c}{\textbf{HANS}} & \multicolumn{2}{c}{\textbf{MNLI}} & \multicolumn{2}{c}{\textbf{Avg.}}  \\
& \emph{base} & \emph{large} & \emph{base} & \emph{large} & \emph{base} & \emph{large} \\
\midrule
BERT & 57.9$_{\pm 1.2}$ & 70.6$_{\pm 2.5}$ & 84.4$_{\pm 0.1}$ & 86.1$_{\pm 0.1}$ & 71.2$_{\pm 0.6}$ & 78.2$_{\pm 1.2}$
\\
BERT +\fbow & 70.4$_{\pm 2.1}$ & 75.7$_{\pm 1.8}$ & 82.5$_{\pm 0.2}$ & 85.3$_{\pm 0.5}$ & 76.5$_{\pm 1.2}$ & 81.4$_{\pm 0.6}$ \\

BERT +\flstm & 69.9$_{\pm 2.2}$ & 76.3$_{\pm 1.7}$ & 82.0$_{\pm 0.2}$ & 85.2$_{\pm 0.6}$ & 76.3$_{\pm 1.3}$ & 80.5$_{\pm 0.6}$ \\

\midrule
XLNET & 71.7$_{\pm 1.9}$ & 76.1$_{\pm 2.7}$ & 86.9$_{\pm 0.1}$ & 89.7$_{\pm 0.1}$ & 79.3$_{\pm 0.9}$ & 82.9$_{\pm 1.3}$ \\

XLNET +\fbow & 78.3$_{\pm 1.1}$ & 83.0$_{\pm 1.4}$ & 85.5$_{\pm 0.1}$ & 87.9$_{\pm 0.5}$ & 81.9$_{\pm 0.4}$ & 85.3$_{\pm 1.0}$ \\

XLNET +\flstm & 78.3$_{\pm 0.6}$ & 83.1$_{\pm 2.9}$ & 85.5$_{\pm 0.1}$ & 87.6$_{\pm 0.4}$ & 81.9$_{\pm 0.4}$ & 85.4$_{\pm 1.7}$ \\
%\midrule
%Roberta & 46.3 & 50.2 & 87.9 & 89.9 &  & 84.15 \\
%Roberta + BoW forgettables & & & & & \\
%Roberta + BiLSTM forgettables & & & & & & \\
\bottomrule
\end{tabular}
\caption{Results of the \emph{base} and \emph{large} version of BERT and XLNET trained on different subset of training examples in MNLI and tested on HANS. Large models not only generalize better to MNLI but are also more robust on HANS.}
\label{tab:bertlarge}
\end{table*}
