
\begin{table}
\setlength{\tabcolsep}{2.5pt}
\footnotesize
\centering
\begin{tabular}{l@{\hskip 0.04in}lccc}
\toprule
& \textbf{Train examples} & \textbf{HANS} & \textbf{MNLI} & \textbf{Avg.}  \\
\midrule
% \small{1} & All & 58.3 & \textbf{84.5} & 71.4        \\
% \small{1} & All & 57.9$_{\pm 1.2}$ & 84.4$_{\pm 0.1}$ &  71.2$_{\pm 0.6}$\\
& \textbf{\bertbase } (lines 1-16) \\
\small{1} & All & 63.1$_{\pm 1.2}$ & 84.5$_{\pm 0.1}$ &  73.8$_{\pm 1.0}$\\
\midrule
\small{2} & \fbert $_{(\balancedbert)}$   & 49.6$_{\pm 0.2}$                     & 37.9$_{\pm 1.3}$                         & 43.7$_{\pm 0.6}$ \\
\small{3} & \hspace{0.2cm} Random $_{(\balancedbert)}$ & 50.8$_{\pm 0.2}$                   & 74.7$_{\pm 0.4}$                         &  62.8$_{\pm 0.1}$ \\
\small{4} & \flstm $_{(\balancedlstm)}$ & 54.0$_{\pm 0.6}$                     & 66.7$_{\pm 0.9}$                         &  60.4$_{\pm 0.2}$  \\
\small{5} & \hspace{0.2cm} Random $_{(\balancedlstm)}$ & 51.3$_{\pm 0.6}$                   & 78.8$_{\pm 0.4}$                         &  65.1$_{\pm 0.3}$  \\
\small{6} & \fbow $_{(\balancedbow)}$    & 55.4$_{\pm 1.4}$                     & 68.2$_{\pm 0.8}$                         &  61.8$_{\pm 1.1}$  \\
\small{7} & \hspace{0.2cm} Random $_{(\balancedbow)}$ & 51.8$_{\pm 0.2}$                 & 79.9$_{\pm 0.4}$                         &   65.9$_{\pm 0.2}$ \\
\midrule
% &\emph{Additional stage of fine-tuning ($\mu_{\pm \sigma}$)} \\
\small{8} & All  + \fbert   
& 68.8$_{\pm 1.8}$ & 83.2$_{\pm 0.3}$ & 76.0$_{\pm 1.1}$  \\
\small{9} & All  + \flstm 
& 70.2$_{\pm 1.1}$ & 83.2$_{\pm 0.4}$ & 76.6$_{\pm 0.8}$ \\
\small{10} & All  + \fbow & 70.4$_{\pm 0.8}$ & 83.3$_{\pm 0.3}$  & 76.8$_{\pm 0.5}$ \\
\small{11} & \hspace{0.2cm} All + Random $_{\balancedbow}$       & 63.6                     & 84.3                        & 73.9  \\
% \midrule
% &\emph{Additional stage of fine-tuning ($\mu_{\pm \sigma}$)} \\
% \small{8} & All + \fbert   
% & 67.4$_{\pm 2.5}$ & 82.0$_{\pm 0.2}$ & 74.7$_{\pm 1.4}$  \\
% \small{9} & All + \flstm 
% & 69.9$_{\pm 2.2}$ & 82.7$_{\pm 0.2}$ & 76.3$_{\pm 1.3}$ \\
% \small{10} & All + \fbow & 70.4$_{\pm 2.1}$ & 82.5$_{\pm 0.2}$  & 76.5$_{\pm 1.2}$ \\
% \small{10-1} & \hspace{0.2cm} All(warmup) + \fbow$_{\balancedbow}$       & 72.0                      & 83.1                         & 77.5  \\
% \small{10-2} & \hspace{0.2cm} All(warmup) + 64k(top loss)       & 71.9                     & 83.3                         & 
% 77.6 \\
% \small{11} & \hspace{0.2cm} All + Random $_{\balancedbow}$       & 60.6                     & 84.1                         & 72.3  \\
\midrule
&\emph{\citet{clark2019dont}} & & & \\
\small{13} & All  (reweight) & 69.2 & 83.5 & 76.4 \\
\small{14} & All (Learned Mixin) & 64.0 & 84.3 & 74.2\\
\midrule
&\emph{\citet{mahabadi2019simple}} & & &  \\
\small{15} & All (Product of Experts) & 66.5 & 84.0 & 75.3     \\
\midrule
&\emph{\citet{he2019unlearn}} & & &  \\
\small{16} & All (DRiFt-HYPO) & 67.1 & 84.3 & 75.7     \\
\midrule
&\emph{\citet{utama2020mind}} & & &  \\
\small{16} & All (Regularized-conf$_{\mbox{\tiny{hans}}}$) & 69.1 & 84.3 & 76.7     \\
\midrule
\midrule 
& \textbf{\bertlarge} (lines 17-20)\\
\small{17} & All &   70.6$_{\pm 2.5}$ & 86.1$_{\pm 0.1}$
& 78.2$_{\pm 1.2}$\\
\small{18} & All + \fbow & 75.7$_{\pm 1.8}$ & 85.3$_{\pm 0.5}$ & 81.4$_{\pm 0.6}$    \\
\small{19} & All + \flstm & 76.3$_{\pm 1.7}$ & 85.2$_{\pm 0.6}$ &
80.5$_{\pm 0.6}$ \\
\small{20} & All + \fbert &    \\

\midrule \midrule
& \textbf{\xlnetbase} (lines 21-24)\\
\small{21} &All & 71.7$_{\pm 1.9}$ & 86.9$_{\pm 0.1}$ & 79.3$_{\pm 0.9}$\\
\small{22} &All +\fbow & 78.3$_{\pm 1.1}$ & 85.5$_{\pm 0.1}$ & 81.9$_{\pm 0.4}$ \\
\small{23} &All +\flstm & 78.3$_{\pm 0.6}$ & 85.5$_{\pm 0.1}$ & 81.9$_{\pm 0.4}$ \\
\midrule \midrule
& \textbf{\xlnetlarge} (lines 24-26)\\
\small{24} & All &   76.1$_{\pm 2.7}$ & 89.7$_{\pm 0.1}$
& 82.9$_{\pm 1.3}$\\
\small{25} & All + \fbow & 83.0$_{\pm 1.4}$ & 87.9$_{\pm 0.5}$ & 85.3$_{\pm 1.0}$    \\
\small{26} & All + \flstm & 83.1$_{\pm 2.9}$ & 87.6$_{\pm 0.4}$ &
85.4$_{\pm 1.7}$ \\
\small{24} & All + \fbert &    \\

\midrule
&\emph{\citet{linzen2019right}} & & &  \\
\small{17} & Estimated MTurks & 76.0 & 92.0 & 84.0 \\
\bottomrule
\end{tabular}
\caption{Results of \bertbase, \bertlarge and \xlnetlarge models trained on different sources of training examples. 
For each line, the accuracy on MNLI dev and HANS and the average of the two is shown. 
We compare performance to the recent baselines in lines 12-14.
The last line shows the reported performance of Mechanical Turks on a sample of MNLI and HANS.}
\label{tab:maintable}
\end{table}
